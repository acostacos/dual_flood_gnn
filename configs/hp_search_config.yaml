dataset_parameters:
  storage_mode: 'memory'                                # 'memory' or 'disk'
  root_dir: 'data/datasets'
  nodes_shp_file: 'Geometry/updated_cell_centers.shp'
  edges_shp_file: 'Geometry/links.shp'
  features_stats_file: 'features_stats.yaml'

  previous_timesteps: 2
  normalize: True
  timestep_interval: 30                                 # Interval between timesteps in seconds (must be a multiple of 30)
  # spin_up_timesteps: 2880                               # Number of timesteps to spin up the model (30 seconds each); Can be defined per Run ID
  spin_up_timesteps:
    1: 4320
    2: 4320
    3: 4320
    4: 4320
    5: 8640
    6: 8640
    7: 8640
    8: 8640
    9: 8640
    10: 8640
    11: 8640
    12: 8640
    13: 10080
    14: 10080
    15: 10080
    16: 10080
  timesteps_from_peak: 250                             # Number of timesteps to consider from the peak (30 seconds each)
  inflow_boundary_nodes:
  - 1248
  outflow_boundary_nodes:
  - 1253
  - 1129

  training:
    dataset_summary_file: 'train.csv'
    event_stats_file: 'train_event_stats.yaml'

  testing:
    dataset_summary_file: 'test.csv'
    event_stats_file: 'test_event_stats.yaml'

training_parameters:
  log_path             : null                                # Path to save training logs
  model_dir            : 'saved_models'                      # Directory to save trained models
  stats_dir            : 'hp_stats'                          # Directory to save training statistics
  num_epochs           : 50                                  # Number of epochs
  batch_size           : 128                                 # Batch size
  learning_rate        : 0.0005                              # Learning rate
  weight_decay         : 0                                   # Weight decay
  autoregressive       : True                               # Use autoregressive training
  autoregressive_timesteps: 8                                # Number of timesteps for autoregressive training
  curriculum_epochs    : 5                                  # Number of epochs before increasing the autoregressive timesteps in curriculum learning

loss_func_parameters:
  edge_pred_loss_percent: 0.3                                # Percentage of edge prediction loss in total loss
  use_global_mass_loss: True                                 # Use global mass conservation in loss function
  use_local_mass_loss: True                                  # Use local mass conservation in loss function
  global_mass_loss_percent: 0.0274                           # Percentage of global mass conservation loss in total loss
  local_mass_loss_percent: 0.0001                            # Percentage of local mass conservation loss in total loss

testing_parameters:
  log_path: null                                        # Path to save testing logs
  output_dir: 'hp_stats'                                # Directory to save testing results
  rollout_start: 0                                      # Start timestep for the test rollout
  rollout_timesteps: null                               # Number of timesteps for the test rollout (30 seconds each)

model_parameters:
  GCN:
    hidden_features: 32
    num_layers: 2
    activation: 'prelu'
    residual: True
    encoder_layers: 2
    encoder_activation: 'prelu'
    decoder_layers: 2
    decoder_activation: 'prelu'

  GAT:
    hidden_features: 32
    use_edge_features: False
    num_layers: 2
    activation: 'prelu'
    residual: True
    num_heads: 1
    dropout: 0.0
    add_self_loops: True
    negative_slope: 0.2
    attn_bias: True
    attn_residual: True
    encoder_layers: 2
    encoder_activation: 'prelu'
    decoder_layers: 2
    decoder_activation: 'prelu'

  NodeEdgeGNN:
    hidden_features: 32
    num_layers: 2
    activation: 'prelu'
    residual: True
    mlp_layers: 2
    encoder_layers: 2
    encoder_activation: 'prelu'
    decoder_layers: 2
    decoder_activation: 'prelu'

  NodeEdgeGNN2:
    hidden_features: 32
    num_layers: 2
    activation: 'prelu'
    residual: True
    mlp_layers: 2
    encoder_layers: 2
    encoder_activation: 'prelu'
    decoder_layers: 2
    decoder_activation: 'prelu'
